# MLForge Credit Card Fraud Detection

A production-ready MLOps project for credit card fraud detection using PyTorch, DVC, and MLflow.

## ğŸ¯ Project Overview

This project implements a neural network-based fraud detection system for credit card transactions. The model is trained on the [Credit Card Fraud Detection dataset](https://www.kaggle.com/mlg-ulb/creditcardfraud) and achieves high recall for identifying fraudulent transactions while managing the severe class imbalance inherent in fraud detection problems.

**Key Features:**
- âœ… **Modular codebase** with separation of concerns
- âœ… **DVC pipeline** for reproducible data processing and training
- âœ… **MLflow tracking** for experiment management
- âœ… **Comprehensive testing** (unit + integration tests)
- âœ… **CI/CD pipeline** with GitHub Actions
- âœ… **Class-weighted loss** to handle imbalanced data

## ğŸ“Š Dataset

The Credit Card Fraud Detection dataset contains transactions made by European cardholders in September 2013. 

**Dataset Statistics:**
- **Total transactions:** 284,807
- **Fraudulent transactions:** 492 (0.172%)
- **Features:** 30 (28 PCA-transformed features + Time + Amount)
- **Target:** Binary classification (0 = Legitimate, 1 = Fraud)

**Class Imbalance:** The dataset is highly imbalanced with fraudulent transactions representing only 0.172% of all transactions. This project addresses this challenge using:
- StandardScaler normalization for Time and Amount features
- Stratified train/test split to preserve class distribution
- Class-weighted BCEWithLogitsLoss during training

## ğŸ—ï¸ Model Architecture

**FraudNet** - A 4-layer feedforward neural network:

```
Input (30 features)
    â†“
Linear(30 â†’ 256) + ReLU
    â†“
Linear(256 â†’ 256) + ReLU
    â†“
Linear(256 â†’ 256) + ReLU
    â†“
Linear(256 â†’ 1) [logits]
    â†“
Sigmoid â†’ Binary prediction
```

**Training Configuration:**
- **Loss Function:** BCEWithLogitsLoss with positive class weighting
- **Optimizer:** Adam (lr=0.005)
- **Epochs:** 100 (configurable via params.yaml)
- **Batch Processing:** Full-batch training

## ğŸ“ Project Structure

```
mlcredit/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Raw dataset (tracked by DVC)
â”‚   â”‚   â””â”€â”€ creditcard.csv
â”‚   â”œâ”€â”€ interim/                # Cleaned data
â”‚   â”‚   â””â”€â”€ clean.csv
â”‚   â””â”€â”€ processed/              # Preprocessed numpy arrays
â”‚       â”œâ”€â”€ X_train.npy
â”‚       â”œâ”€â”€ X_test.npy
â”‚       â”œâ”€â”€ y_train.npy
â”‚       â””â”€â”€ y_test.npy
â”œâ”€â”€ models/
â”‚   â””â”€â”€ model.pt                # Trained PyTorch model
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ metrics.json            # Evaluation metrics
â”‚   â””â”€â”€ figures/
â”‚       â””â”€â”€ confusion_matrix.png
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ model.py                # FraudNet architecture
â”‚   â”œâ”€â”€ load_data.py            # Data loading stage
â”‚   â”œâ”€â”€ preprocess.py           # Preprocessing stage
â”‚   â”œâ”€â”€ train.py                # Training stage
â”‚   â””â”€â”€ evaluate.py             # Evaluation stage
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_data_pipeline.py   # Data pipeline tests
â”‚   â”œâ”€â”€ test_training.py        # Training tests
â”‚   â””â”€â”€ test_model_artifact.py  # Artifact validation tests
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ ci.yml              # CI/CD pipeline
â”œâ”€â”€ dvc.yaml                    # DVC pipeline definition
â”œâ”€â”€ params.yaml                 # Configuration parameters
â”œâ”€â”€ requirements.txt            # Python dependencies
â””â”€â”€ README.md                   # This file
```

## ğŸš€ Getting Started

### Prerequisites

- Python 3.9+
- Git
- (Optional) DVC remote storage for data versioning

### Installation

1. **Clone the repository:**
```bash
git clone <repository-url>
cd mlcredit
```

2. **Install dependencies:**
```bash
pip install -r requirements.txt
```

3. **Place the dataset:**
```bash
# Download creditcard.csv and place it in data/raw/
mkdir -p data/raw
# Copy your creditcard.csv to data/raw/
```

4. **Initialize DVC (optional):**
```bash
dvc init
dvc add data/raw/creditcard.csv
```

5. **Configure DVC Remote (if using Google Drive):**
The project is configured to use Google Drive. You may need to authenticate:
```bash
# This will trigger an authentication flow in your browser
dvc pull
```
If that doesn't work, you might need to configure your own remote:
```bash
dvc remote add -d storage gdrive://<YOUR_FOLDER_ID>
```

## ğŸ”„ Running the Pipeline

### Option 1: Run Complete DVC Pipeline

Execute all stages (load â†’ preprocess â†’ train â†’ evaluate):

```bash
dvc repro
```

This will:
1. Load and validate raw data
2. Apply feature scaling and train/test split
3. Train the FraudNet model with MLflow tracking
4. Evaluate the model and generate metrics + visualizations

### Option 2: Run Individual Stages

**Data Loading:**
```bash
python src/load_data.py
```

**Preprocessing:**
```bash
python src/preprocess.py
```

**Training:**
```bash
python src/train.py
```

**Evaluation:**
```bash
python src/evaluate.py
```

## ğŸ“ˆ MLflow Experiment Tracking

### View Experiments

Start the MLflow UI:
```bash
mlflow ui
```

Then open your browser to `http://localhost:5000`

### What's Tracked

**Parameters:**
- Model architecture (input_features, hidden_units, output_features)
- Training config (epochs, learning_rate, random_seed)
- Data split (test_size)
- Class weights (pos_weight)

**Metrics (per epoch):**
- train_loss, train_acc
- test_loss, test_acc

**Artifacts:**
- model.pt (trained model state dict)
- metrics.json (evaluation metrics)
- confusion_matrix.png (visualization)

## ğŸ§ª Testing

### Run All Tests

```bash
pytest tests/ -v
```

### Run Specific Test Suites

**Data Pipeline Tests:**
```bash
pytest tests/test_data_pipeline.py -v
```

**Training Tests:**
```bash
pytest tests/test_training.py -v
```

**Model Artifact Tests:**
```bash
pytest tests/test_model_artifact.py -v
```

### Test Coverage

The test suite includes:
- âœ… Data loading and validation
- âœ… Preprocessing and feature scaling
- âœ… Train/test split verification
- âœ… Model training with epoch override
- âœ… Model architecture validation
- âœ… Evaluation metrics validation
- âœ… Artifact existence and format checks

## âš™ï¸ Configuration

All configuration is centralized in `params.yaml`:

```yaml
# Data paths
data:
  raw: data/raw/creditcard.csv
  interim: data/interim/clean.csv
  processed: { ... }

# Model architecture
model:
  input_features: 30
  hidden_units: 256
  output_features: 1

# Training configuration
training:
  epochs: 100
  learning_rate: 0.005
  random_seed: 42

# MLflow configuration
mlflow:
  experiment_name: credit-fraud-detection
  tracking_uri: ./mlruns
```

### Environment Variables

**N_EPOCHS_OVERRIDE:** Override the number of training epochs (useful for CI/CD)

```bash
N_EPOCHS_OVERRIDE=2 python src/train.py
```

## ğŸ”„ CI/CD Pipeline

The project includes a GitHub Actions workflow (`.github/workflows/ci.yml`) that:

1. âœ… Sets up Python 3.9 environment
2. âœ… Installs dependencies with caching
3. âœ… Pulls DVC data (with graceful fallback)
4. âœ… Runs pytest test suite
5. âœ… Executes DVC pipeline with epoch override (N_EPOCHS_OVERRIDE=2)
6. âœ… Uploads model and metrics as artifacts

**Triggers:**
- Push to `main` or `develop` branches
- Pull requests to `main`

**Artifacts Uploaded:**
- `trained-model` (models/model.pt)
- `evaluation-metrics` (reports/)
- `mlflow-runs` (mlruns/)

## ğŸ“Š Evaluation Metrics

After running the evaluation stage, metrics are saved to `reports/metrics.json`:

```json
{
  "precision": 0.XXXX,
  "recall": 0.XXXX,
  "f1_score": 0.XXXX,
  "accuracy": 0.XXXX
}
```

**Confusion Matrix:** A visualization is saved to `reports/figures/confusion_matrix.png` showing:
- True Negatives (legitimate transactions correctly identified)
- False Positives (legitimate transactions flagged as fraud)
- False Negatives (fraudulent transactions missed)
- True Positives (fraudulent transactions correctly identified)

## ğŸ”§ Development

### Adding New Features

1. Update `params.yaml` with new configuration
2. Modify relevant source files in `src/`
3. Update `dvc.yaml` if pipeline stages change
4. Add tests in `tests/`
5. Run tests: `pytest tests/ -v`
6. Run pipeline: `dvc repro`

### Modifying Model Architecture

Edit `src/model.py` and update the `FraudNet` class. Remember to:
- Update `params.yaml` if new hyperparameters are added
- Retrain the model: `dvc repro train`
- Re-evaluate: `dvc repro evaluate`

## ğŸ“ Original Implementation

The original single-file implementation is preserved as `creditfraud.py` for reference.

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License.

## ğŸ™ Acknowledgments

- Dataset: [Kaggle Credit Card Fraud Detection](https://www.kaggle.com/mlg-ulb/creditcardfraud)
- Original research: Andrea Dal Pozzolo et al.

## ğŸ“ Support

For issues, questions, or contributions, please open an issue on GitHub.

---

**Built with â¤ï¸ using PyTorch, DVC, and MLflow**
